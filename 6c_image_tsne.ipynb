{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: data/101_ObjectCategories/accordion/image_0001.jpg, features: -7.55,-6.28,-21.75,5.71... \n",
      "image: data/101_ObjectCategories/accordion/image_0002.jpg, features: -8.51,-8.37,-17.40,-4.45... \n",
      "image: data/101_ObjectCategories/accordion/image_0003.jpg, features: -11.12,-10.11,-21.06,7.69... \n",
      "image: data/101_ObjectCategories/accordion/image_0004.jpg, features: -12.16,-11.77,-21.84,7.25... \n",
      "image: data/101_ObjectCategories/accordion/image_0005.jpg, features: -9.15,-3.14,-13.55,-0.50... \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "images, pca_features, pca = pickle.load(open('data/features_caltech101.p', 'rb'))\n",
    "\n",
    "for i, f in list(zip(images, pca_features))[0:5]:\n",
    "    print(\"image: %s, features: %0.2f,%0.2f,%0.2f,%0.2f... \"%(i, f[0], f[1], f[2], f[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_to_plot = 1000\n",
    "\n",
    "if len(images) > num_images_to_plot:\n",
    "    sort_order = sorted(random.sample(xrange(len(images)), num_images_to_plot))\n",
    "    images = [images[i] for i in sort_order]\n",
    "    pca_features = [pca_features[i] for i in sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X = np.array(pca_features)\n",
    "tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "full_image = Image.new('RGBA', (width, height))\n",
    "for img, x, y in tqdm(zip(images, tx, ty)):\n",
    "    tile = Image.open(img)\n",
    "    rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "    tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)\n",
    "    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "\n",
    "matplotlib.pyplot.figure(figsize = (16,12))\n",
    "imshow(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image.save(\"example-tSNE-caltech101.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_path = \"../data/example-tSNE-points-animals.json\"\n",
    "\n",
    "data = [{\"path\":os.path.abspath(img), \"point\":[x, y]} for img, x, y in zip(images, tx, ty)]\n",
    "with open(tsne_path, 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "\n",
    "print(\"saved t-SNE result to %s\" % tsne_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterfairy\n",
    "\n",
    "# nx * ny = 1000, the number of images\n",
    "nx = 40\n",
    "ny = 25\n",
    "\n",
    "# assign to grid\n",
    "grid_assignment = rasterfairy.transformPointCloud2D(tsne, target=(nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_width = 72\n",
    "tile_height = 56\n",
    "\n",
    "full_width = tile_width * nx\n",
    "full_height = tile_height * ny\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "grid_image = Image.new('RGB', (full_width, full_height))\n",
    "\n",
    "for img, grid_pos in tqdm(zip(images, grid_assignment)):\n",
    "    idx_x, idx_y = grid_pos\n",
    "    x, y = tile_width * idx_x, tile_height * idx_y\n",
    "    tile = Image.open(img)\n",
    "    tile_ar = float(tile.width) / tile.height  # center-crop the tile to match aspect_ratio\n",
    "    if (tile_ar > aspect_ratio):\n",
    "        margin = 0.5 * (tile.width - aspect_ratio * tile.height)\n",
    "        tile = tile.crop((margin, 0, margin + aspect_ratio * tile.height, tile.height))\n",
    "    else:\n",
    "        margin = 0.5 * (tile.height - float(tile.width) / aspect_ratio)\n",
    "        tile = tile.crop((0, margin, tile.width, margin + float(tile.width) / aspect_ratio))\n",
    "    tile = tile.resize((tile_width, tile_height), Image.ANTIALIAS)\n",
    "    grid_image.paste(tile, (int(x), int(y)))\n",
    "\n",
    "matplotlib.pyplot.figure(figsize = (16,12))\n",
    "imshow(grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_image.save(\"../assets/example-tSNE-grid-animals.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
